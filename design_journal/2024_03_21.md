# 2024-03-21: Conversion of Wiki to Jekyll - Missing Image Files

## Summary

I resolved issue [#56](https://github.com/dfhawthorne/dfhawthorne.github.io/issues/56) by replacing the affected pages with their New Google Sites version.

## Table of Contents

* [Issues](#issues)
  * [56: Unable to locate image file, 'perform.html'](#56-unable-to-locate-image-file-performhtml)
    * [Initial Design Idea](#initial-design-idea)
    * [Download New Google Sites Version](#download-new-google-sites-version)
    * [Location of Image Files in New Google Sites Version](#location-of-image-files-in-new-google-sites-version)
    * [Find All Referenced Image File](#find-all-referenced-image-file)
    * [Clean Up Unneeded Files](#clean-up-unneeded-files)
    * [Replace Pages with New Google Sites Version](#replace-pages-with-new-google-sites-version)
* [Conversion Script](#conversion-script)
  * [NORMALISE_URL Function Changes](#normalise_url-function-changes)
  * [URL Normalisation](#url-normalisation)
  * [Image Anchor Address Tags](#image-anchor-address-tags)
  * [Use of os.path.sep](#use-of-ospathsep)

## Issues

### 56: Unable to locate image file, 'perform.html'

I ended up in replacing the affected pages with their New Google Sites versions. This issue is resolved.

#### Initial Design Idea

This issue ([#56](https://github.com/dfhawthorne/dfhawthorne.github.io/issues/56)) was introduced in commit 03734a3 when a fix was added. The design journal entry for [2024-02-21](2024_02_21.md) does not explain the reasons for doing so.

As far as I can remember, the issue was that there were links to the base name of a page, instead of the full name. That is, there were links of the kind:

```html
<a href="home/blah/blah/page">Page Name</a>
```

Instead of

```html
<a href="home/blah/blah/page.html">Page Name</a>
```

This proved pointless as the image files were missing.

#### Download New Google Sites Version

I followed the procedures in "[Technical Note: Core Dump for WGET2 if Compression not Specified](https://yaocm.wordpress.com/2024/03/21/technical-note-core-dump-for-wget2-if-compression-not-specified/)" to download the New Google Sites Version of my Wiki into `~/Documents/yaocm/sites.google.com/site/yetanotherocm`.

I used the following commands to determine what files are available in the `emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics` directory:

```bash
cd ~/Documents/yaocm/sites.google.com/site/yetanotherocm2/sites.google.com/view/yetanotherocm/home/12c-ocp-upgrade/section-1-new-features-of-oracle-database-12c/emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics
file *
```

The results were:

```text
diagnose-performance-issues-using-ash-enhancements: HTML document, Unicode text, UTF-8 text, with very long lines (32080)
generate-addm-compare-period:                       HTML document, Unicode text, UTF-8 text, with very long lines (32256)
perform-emergency-monitoring-and-real-time-addm:    HTML document, Unicode text, UTF-8 text, with very long lines (32122)
```

The HTML files do not have the `.html` suffix.

#### Location of Image Files in New Google Sites Version

I ran the following commands to see the location of image files from the New Google Sites version of my Wiki:

```bash
hxnormalize -xe perform-emergency-monitoring-and-real-time-addm | \
    hxselect -s '\n' img | \
    sed -nre 's!.*src="([^"]+)".*!\1!p'
```

The results were:

```text
https://lh4.googleusercontent.com/w7YXPq-qAriPtp1h6WBP8lw8thUOSK1uK0l1NGRy5JwEblr-wHZ3Gtghjmr8b_9CrzTpdDX--w5HlaanifS-Rnk7Y1-bCFAgXa-Q3xC0ER2RHZe6=w1280
https://lh3.googleusercontent.com/n69NPFyfOyVdsGVXOVC3_lNUTVSDSZpd1W5N67UxnKGUY880UbdIYtYK3evcH-_Ctmv8GjAlHbYInmPQdmzZCBvqylNNkuKbr_YdNDdifkkjijpu=w1280
https://lh4.googleusercontent.com/GBaDNEM81COaSzQsY2PQciV-L8mCLvQxmeT01pvyrc3yfpjhT0X9Q3GN_vUxhjlsQCImHKTQyaywlhfkXf-kkjOLOJR5pe73XguEbOCsv3a72Hmq=w1280
https://lh3.googleusercontent.com/UqPaBa1GAdUe0-6VRnv5Knu31_VPidBhQ2Ws0l0WSigmfUhQl5Im54xk4OjZG1Aat9RCXqrXIifGhRGUjnBvMzoJgMdd-36n0yHi4HVm3CNsIblI=w1280
https://lh5.googleusercontent.com/-mdBcpa9XLPOGeiRNdb-5M6XFDDvlzIGT013eU5Vj18bnYSINTdc7NBJL7DYFf9kV2NwlvS80hSde0dnbJyv1KhMI08TYjp2dzrK5MKI6xEwKzxW=w1280
https://lh5.googleusUse of os.path.sepercontent.com/kzS_agR8p_sm0MOUn1rzbaSxohRi1tmfX452GzXjQXret5bymA2eKwcjr3OxQhpFgMzCHT8HEZd7h6Uei-9KIcxfqX73C18NsOrZvmnyyQuXj7wa=w1280
https://lh6.googleusercontent.com/2ux4uMljyU0SRbqlItKq4K_U23aurqFLC_eEgHwr3CQRhIbhJ-X7m2uqJrjsLuoKodYpSo8tw6xVDGSX9Mf-mbNXARVfVLgAuHpK3FL85T4RpMBA=w1280
https://lh3.googleusercontent.com/wVhYrjqgT5hxPVnEUCcq3wCXFwCpTdjol5MfNfiFzIpATslqKpqUowuMX6Wvk8smg-QmDXIKxFlat3YIdmjPjXMPXUmbAbEu9IC38gaADdioSdb3=w1280
https://lh5.googleusercontent.com/QptE54ce_dxERdXPtQauUyrk2U7OIPvI376TK73XVnJPUBqt0S98L4gjcafGJ5OFrV-Yuu1pCF9XpNFV0lXbLuFhZaagwXho9cR8sQXgsZqIqEcT=w1280
https://lh5.googleusercontent.com/WxJsRkA_VN_mjpsh1DQHHWd2UeqbRbBdlbkrPDfL1T6jvBWMWXATcu8qD5Dm1L2BNFy9vMNh4hBZ4-5TegVxRb3bE2xVwDJXn6uG69VjYQi5hqMg=w1280
https://lh3.googleusercontent.com/-5t7-knfkWIzIG5ZrTSI2vBDctD3QfXtq1y7NvU2cZnLOryqMf4tJEsM0uIScTJy5mTOBUks-QwL-HeEj29ezvfyR3ekJQq9OIWfvcV8PYEF8eMn=w1280
https://lh5.googleusercontent.com/YPO5M7O9OHDAlQ8XwFFyWLfVHsOscip0LZOZ6VFFULvS0ejV8PgnmWD5hFeRSEQ5OaLmuOcQbtYNQFD6Nyh-80VnBj06eMYvxGcaUUfYco4rpaCu=w1280
```

The image files are all outside of the New Google Sites version of my Wiki. I will have to decide what to do about them. I raised issue #[62](https://github.com/dfhawthorne/dfhawthorne.github.io/issues/62) to remind me to consider this later.

#### Find All Referenced Image File

I ran the following commands to find all of the referenced image files in the `perform-emergency-monitoring.html` page:

```bash
hxnormalize -xe perform-emergency-monitoring.html | \
    hxselect -s '\n' a | \
    sed -nre 's!.*href="([^"]+)".*imageanchor.*!\1!p' | \
    cut -d/ -f9
```

The following file names were extracted. None of them were found in the `emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics` directory:

```text
OEM_Emergency_Monitor_Access.png?attredirects=0
OEM_Emergency_Monitor_Credentials.png?attredirects=0
OEM_Emergency_Page.png?attredirects=0
OEM_RT_ADDM_Access.png?attredirects=0
OEM_RT_ADDM_Credentials.png?attredirects=0
OEM_RT_ADDM_Page_1.png?attredirects=0
OEM_RT_ADDM_Page_2.png?attredirects=0
OEM_RT_ADDM_Page_3.png?attredirects=0
OEM_RT_ADDM_Page_4.png?attredirects=0
OEM_RT_ADDM_Page_5.png?attredirects=0
OEM_RT_ADDM_Page_6.png?attredirects=0
OEM_RT_ADDM_Page_7.png?attredirects=0
```

#### Clean Up Unneeded Files

I ran the following commands to clean up the `emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics` directory:

```bash
cd docs/home/12c-ocp-upgrade/section-1-new-features-of-oracle-database-12c/emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics
git rm 'access_compare_addm_via_oem.png'
git rm 'diagnos'
git rm 'diagnose-performance-issues-'
git rm 'diagnose-performance-issues-.html'
git rm 'error_msg.png'
git rm 'fill_in_compare_addm_period_parm.png'
git rm 'generat'
git rm 'generate-addm-compare-period.png'
git rm 'perform'
git rm 'perform-emergency-monitoring'
git rm 'perform-emergency-monitoring.html'
```

#### Replace Pages with New Google Sites Version

I ran the following commands to replace the pages in the `emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics` directory with the New Google Sites version:

```bash
cd yetanotherocm/home/12c-ocp-upgrade/section-1-new-features-of-oracle-database-12c/emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics
for f in *
do cp -f "${f}" \
    ~/git-repositories/dfhawthorne.github.io/docs/home/12c-ocp-upgrade/section-1-new-features-of-oracle-database-12c/emergency-monitoring-real-time-addm-compare-period-addm-and-active-session-history-ash-analytics/"${f}.html"
done
```

## Conversion Script

I made several changes to the conversion script, `scripts/convert_web_page.py`:

1. NORMALISE_URL Function Changes
1. Address Tag Processing
1. Image Anchor Address Tags
1. Use of os.path.sep

### NORMALISE_URL Function Changes

The `normalise_url` function:

* Does not append `.html` to the URL if the file, without the suffix, exists;
* Only appends `.html` to the URL if the resulting file name exists;
* Otherwise, prints an error and causes the program to exit.

### URL Normalisation

URL normalisation is done separately before any other processing, such as unwrapping or scheduling for removal, or movement. The old code was too complicated to work with.

### Image Anchor Address Tags

Address tags with the `imageanchor` attribute are processed separately after URL normalisation. These tags wrap an image tag. There are usually two (2) different URLs, especially with long file names. The image `SRC` attribute is truncated in these cases. Thus, the HREF attribute is more accurate. Sometimes, the SRC attribute of the image tag points to an existing file.

The URL is stripped of any queries. If the resulting URL points to a file, then:

1. If needed, a `git mv` command is scheduled to do the renaming.
1. The enclosed image tag is unwrapped;
1. The `SRC` attribute is updated with the stripped URL.
1. The original image source is scheduled for removal, if it is different from new one
1. If the new source is not a file, an error message is printed and the program exits.

### Use of os.path.sep

All occurrences of '/' in file name constructions were replaced with `os.path.sep`. This reinforces the habit of writing portable code.
