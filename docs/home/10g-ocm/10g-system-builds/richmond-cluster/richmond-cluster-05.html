---
layout: default
title: Richmond Cluster (05)
base-url: home/10g-ocm/10g-system-builds/richmond-cluster/richmond-cluster-05.html
breadcrumbs:
- title: Home
  url: home.html
- title: 10G OCM
  url: home/10g-ocm.html
- title: 10G System Builds
  url: home/10g-ocm/10g-system-builds.html
- title: Richmond Cluster
  url: home/10g-ocm/10g-system-builds/richmond-cluster.html
- title: Richmond Cluster (05)
  url: home/10g-ocm/10g-system-builds/richmond-cluster/richmond-cluster-05.html
scroll-bar:
  left-link:
    url: /home/10g-ocm/10g-system-builds/richmond-cluster/richmond-cluster-04.html
    title: Richmond Cluster (04)
  right-link:
    url: home/10g-ocm/10g-system-builds/richmond-cluster/richmond-cluster-06.html
    title: Richmond Cluster (06)
---
<div dir="ltr">
 <p style="FONT-SIZE:smaller;FONT-STYLE:italic">
  Saturday 03 May, 2008 - 09:45
 </p>
 <p>
  Set up the ssh user equivalency between
  <b>
   central
  </b>
  ,
  <b>
   richmond1
  </b>
  , and
  <b>
   richmond2
  </b>
  by going to
  <b>
   central
  </b>
  to download the ssh public keys from the other servers:
  <br/>
  <code>
   $ su - oracle
   <br/>
   $ cd .ssh
   <br/>
   $ rm known_hosts (stops conflict over the same IP address)
   <br/>
   $ sftp richmond1-mgt
   <br/>
   cd .ssh
   <br/>
   get id_dsa.pub richmond1_dsa.pub
   <br/>
   get id_rsa.pub richmond1_rsa.pub
   <br/>
   exit
  </code>
 </p>
 <p>
  Repeated for
  <b>
   richmond2
  </b>
  .
 </p>
 <p>
  Create a single repository for all public keys for oracle on
  <b>
   central
  </b>
  , then copied to the other servers:
  <br/>
  <code>
   $ su - oracle
   <br/>
   $ cd .ssh
   <br/>
   $ cat *.pub &gt;authorized_keys
  </code>
  (overwrites previous version of authorized_keys)
  <code>
   <br/>
   $ scp authorized_keys richmond1-mgt:.ssh/
   <br/>
   $ scp authorized_keys richmond2-mgt:.ssh/
  </code>
 </p>
 <p>
  On each of
  <b>
   central
  </b>
  ,
  <b>
   richmond1
  </b>
  , and
  <b>
   richmond2
  </b>
  , establish the bona-fides of the servers to each other (including itself to itself) by executing the following series of commands (the date command is just a simple command to execute and return to the calling host):
  <br/>
  <code>
   ssh-agent $SHELL
   <br/>
   ssh-add
   <br/>
   ssh central date
   <br/>
   ssh central.yaocm.id.au date
   <br/>
   ssh richmond1 date
   <br/>
   ssh richmond1.yaocm.id.au date
   <br/>
   ssh richmond1-mgt date
   <br/>
   ssh richmond1-mgt.yaocm.id.au date
   <br/>
   ssh richmond2 date
   <br/>
   ssh richmond2.yaocm.id.au date
   <br/>
   ssh richmond2-mgt date
   <br/>
   ssh richmond2-mgt.yaocm.id.au date
  </code>
 </p>
 <p>
  Now to load the clusterware installation software on both
  <b>
   richmond1
  </b>
  and
  <b>
   richmond2
  </b>
  :
  <br/>
  <code>
   $ su - oracle
   <br/>
   $ mkdir installation
   <br/>
   $ cd installation
   <br/>
   $ unzip /mnt/hgfs/OCM/10201_clusterware_linux32.zip
  </code>
 </p>
 <p>
  Installed
  <code>
   cvuqdisk
  </code>
  package on both
  <b>
   richmond1
  </b>
  and
  <b>
   richmond2
  </b>
  :
  <br/>
  <code>
   $ su -
   <br/>
   # cd /home/oracle/installation/clusterware/rpm
   <br/>
   # ls
   <br/>
   cvuqdisk-1.0.1-1.rpm
   <br/>
   # rpmquery cvuqdisk
   <br/>
   package cvuqdisk is not installed
   <br/>
   # export CVUQDISK_GRP=oinstall
   <br/>
   # rpm -iv cvuqdisk-1.0.1-1.rpm
   <br/>
   Preparing packages for installation...
   <br/>
   cvuqdisk-1.0.1-1
   <br/>
   # rpmquery cvuqdisk
   <br/>
   cvuqdisk-1.0.1-1
  </code>
 </p>
 <p>
  On
  <b>
   richmond1
  </b>
  ,
  <br/>
  <code>
   $ su -
   <br/>
   # parted /dev/sdb
   <br/>
   GNU Parted 1.6.3
   <br/>
   ...
   <br/>
   Using /dev/sdb
   <br/>
   Error: Unable to open /dev/sdb - unrecognised disk label.
   <br/>
   Information: The operating system thinks the geometry on /dev/sdb is 261/255/63.
   <br/>
   (parted) mklabel gpt
   <br/>
   (parted) mkpart primary ext3 0 200
   <br/>
   (parted) mkpart primary ext3 200 250
   <br/>
   (parted) print
   <br/>
   Disk geometry for /dev/sdb: 0.000-2048.000 megabytes
   <br/>
   Disk label type: gpt
   <br/>
   Minor Start End Filesystem Name Flags
   <br/>
   1 0.017 200.000
   <br/>
   2 200.000 250.000
   <br/>
   (parted) select /dev/sdc
   <br/>
   Using /dev/sdc
   <br/>
   Error: Unable to open /dev/sdc - unrecognised disk label.
   <br/>
   Information: The operating system thinks the geometry on /dev/sdc is 261/255/63.
   <br/>
   (parted) mklabel gpt
   <br/>
   (parted) mkpart primary ext3 0 200
   <br/>
   (parted) mkpart primary ext3 200 250
   <br/>
   (parted) print
   <br/>
   Disk geometry for /dev/sdc: 0.000-2048.000 megabytes
   <br/>
   Disk label type: gpt
   <br/>
   Minor Start End Filesystem Name Flags
   <br/>
   1 0.017 200.000
   <br/>
   2 200.000 250.000
   <br/>
   (parted) select /dev/sdd
   <br/>
   Using /dev/sdd
   <br/>
   Error: Unable to open /dev/sdd - unrecognised disk label.
   <br/>
   Information: The operating system thinks the geometry on /dev/sdd is 261/255/63.
   <br/>
   (parted) mklabel gpt
   <br/>
   (parted) mkpart primary ext3 0 200
   <br/>
   (parted) mkpart primary ext3 200 250
   <br/>
   (parted) print
   <br/>
   Disk geometry for /dev/sdd: 0.000-2048.000 megabytes
   <br/>
   Disk label type: gpt
   <br/>
   Minor Start End Filesystem Name Flags
   <br/>
   1 0.017 200.000
   <br/>
   2 200.000 250.000
   <br/>
   (parted) quit
   <br/>
   Information: Don't forget to update /etc/fstab, if necessary.
  </code>
 </p>
 <p>
  However when I use parted on
  <b>
   richmond2
  </b>
  , I get the following:
  <br/>
  <code>
   $ su -
   <br/>
   # parted /dev/sdb
   <br/>
   ...
   <br/>
   Using /dev/sdb
   <br/>
   Warning: /dev/sdb contains GPT signatures, indicating that it has a GPT table. However, it does not have a valid fake msdos
   <br/>
   partition table, as it should. Perhaps it was corrupted - possibly by a program that doesn't understand GPT partition
   <br/>
   tables. Or perhaps you deleted the GPT table, and are now using an msdos partition table. Is this a GPT partition table?
   <br/>
   Yes/No? yes
   <br/>
   Error: The primary GPT table is corrupt, but the backup appears ok, so that will be used.
   <br/>
   OK/Cancel? OK
   <br/>
   Information: The operating system thinks the geometry on /dev/sdb is 261/255/63.
   <br/>
   (parted) print
   <br/>
   Disk geometry for /dev/sdb: 0.000-2048.000 megabytes
   <br/>
   Disk label type: gpt
   <br/>
   Minor Start End Filesystem Name Flags
   <br/>
   1 0.017 200.000
   <br/>
   2 200.000 250.000
  </code>
 </p>
 <p>
  This was also true for
  <code>
   /dev/sdc
  </code>
  and
  <code>
   /dev/sdd
  </code>
  as well. But this occurred only the first time on
  <b>
   richmond2
  </b>
  .
 </p>
 <p>
  At this stage, I should be ready to install the clusterware. So, I run a preinstallation check:
  <br/>
  <code>
   $ su - oracle
   <br/>
   $ cd ~/installation/clusterware/cluvfy
   <br/>
   $ ./runcluvfy stage -pre crsinst -n richmond1,richmond2 -r 10gR2 -c /dev/sdb1 -q /dev/sdb2 -osdba dba -oinv oinstall -verbose
   <br/>
   Performing pre-checks for cluster services setup
   <br/>
   <br/>
   Checking node reachability...
   <br/>
   <br/>
   Check: Node reachability from node "richmond1"
   <br/>
   Destination Node Reachable?
   <br/>
   ------------------------------------ ------------------------
   <br/>
   richmond2 yes
   <br/>
   richmond1 yes
   <br/>
   Result: Node reachability check passed from node "richmond1".
   <br/>
   <br/>
   <br/>
   Checking user equivalence...
   <br/>
   <br/>
   Check: User equivalence for user "oracle"
   <br/>
   Node Name Comment
   <br/>
   ------------------------------------ ------------------------
   <br/>
   richmond2 passed
   <br/>
   richmond1 passed
   <br/>
   Result: User equivalence check passed for user "oracle".
   <br/>
   <br/>
   Checking administrative privileges...
   <br/>
   <br/>
   Check: Existence of user "oracle"
   <br/>
   Node Name User Exists Comment
   <br/>
   ------------ ------------------------ ------------------------
   <br/>
   richmond2 yes passed
   <br/>
   richmond1 yes passed
   <br/>
   Result: User existence check passed for "oracle".
   <br/>
   <br/>
   Check: Existence of group "oinstall"
   <br/>
   Node Name Status Group ID
   <br/>
   ------------ ------------------------ ------------------------
   <br/>
   richmond2 exists 600
   <br/>
   richmond1 exists 600
   <br/>
   Result: Group existence check passed for "oinstall".
   <br/>
   <br/>
   Check: Membership of user "oracle" in group "oinstall" [as Primary]
   <br/>
   Node Name User Exists Group Exists User in Group Primary Comment
   <br/>
   ---------------- ------------ ------------ ------------ ------------ ------------
   <br/>
   richmond2 yes yes yes yes passed
   <br/>
   richmond1 yes yes yes yes passed
   <br/>
   Result: Membership check for user "oracle" in group "oinstall" [as Primary] passed.
   <br/>
   <br/>
   Administrative privileges check passed.
   <br/>
   <br/>
   Checking node connectivity...
   <br/>
   <br/>
   <br/>
   Interface information for node "richmond2"
   <br/>
   Interface Name IP Address Subnet
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   eth0 192.168.100.66 192.168.100.0
   <br/>
   eth1 192.168.101.2 192.168.101.0
   <br/>
   <br/>
   <br/>
   Interface information for node "richmond1"
   <br/>
   Interface Name IP Address Subnet
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   eth0 192.168.100.65 192.168.100.0
   <br/>
   eth1 192.168.101.1 192.168.101.0
   <br/>
   <br/>
   <br/>
   Check: Node connectivity of subnet "192.168.100.0"
   <br/>
   Source Destination Connected?
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2:eth0 richmond1:eth0 yes
   <br/>
   Result: Node connectivity check passed for subnet "192.168.100.0" with node(s) richmond2,richmond1.
   <br/>
   <br/>
   Check: Node connectivity of subnet "192.168.101.0"
   <br/>
   Source Destination Connected?
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2:eth1 richmond1:eth1 yes
   <br/>
   Result: Node connectivity check passed for subnet "192.168.101.0" with node(s) richmond2,richmond1.
   <br/>
   <br/>
   Suitable interfaces for the private interconnect on subnet "192.168.100.0":
   <br/>
   richmond2 eth0:192.168.100.66
   <br/>
   richmond1 eth0:192.168.100.65
   <br/>
   <br/>
   Suitable interfaces for the private interconnect on subnet "192.168.101.0":
   <br/>
   richmond2 eth1:192.168.101.2
   <br/>
   richmond1 eth1:192.168.101.1
   <br/>
   <br/>
   ERROR:
   <br/>
   Could not find a suitable set of interfaces for VIPs.
   <br/>
   <br/>
   Result: Node connectivity check failed.
   <br/>
   <br/>
   <br/>
   Checking shared storage accessibility...
   <br/>
   <br/>
   ERROR: /dev/sdb1
   <br/>
   Unable to determine the sharedness of /dev/sdb on nodes:
   <br/>
   richmond2,richmond1
   <br/>
   <br/>
   Shared storage check failed on nodes "richmond2,richmond1".
   <br/>
   <br/>
   Checking shared storage accessibility...
   <br/>
   <br/>
   ERROR: /dev/sdb2
   <br/>
   Unable to determine the sharedness of /dev/sdb on nodes:
   <br/>
   richmond2,richmond1
   <br/>
   <br/>
   <br/>
   Shared storage check failed on nodes "richmond2,richmond1".
   <br/>
   <br/>
   Checking system requirements for 'crs'...
   <br/>
   <br/>
   Check: Total memory
   <br/>
   Node Name Available Required Comment
   <br/>
   ------------ ------------------------ ------------------------ ----------
   <br/>
   richmond2 1003.38MB (1027460KB) 512MB (524288KB) passed
   <br/>
   richmond1 1003.38MB (1027460KB) 512MB (524288KB) passed
   <br/>
   Result: Total memory check passed.
   <br/>
   <br/>
   Check: Free disk space in "/tmp" dir
   <br/>
   Node Name Available Required Comment
   <br/>
   ------------ ------------------------ ------------------------ ----------
   <br/>
   richmond2 3.22GB (3376644KB) 400MB (409600KB) passed
   <br/>
   richmond1 3.14GB (3289632KB) 400MB (409600KB) passed
   <br/>
   Result: Free disk space check passed.
   <br/>
   <br/>
   Check: Swap space
   <br/>
   Node Name Available Required Comment
   <br/>
   ------------ ------------------------ ------------------------ ----------
   <br/>
   richmond2 1.95GB (2040244KB) 1GB (1048576KB) passed
   <br/>
   richmond1 1.95GB (2040244KB) 1GB (1048576KB) passed
   <br/>
   Result: Swap space check passed.
   <br/>
   <br/>
   Check: System architecture
   <br/>
   Node Name Available Required Comment
   <br/>
   ------------ ------------------------ ------------------------ ----------
   <br/>
   richmond2 i686 i686 passed
   <br/>
   richmond1 i686 i686 passed
   <br/>
   Result: System architecture check passed.
   <br/>
   <br/>
   Check: Kernel version
   <br/>
   Node Name Available Required Comment
   <br/>
   ------------ ------------------------ ------------------------ ----------
   <br/>
   richmond2 2.4.21-40.EL 2.4.21-15EL passed
   <br/>
   richmond1 2.4.21-40.EL 2.4.21-15EL passed
   <br/>
   Result: Kernel version check passed.
   <br/>
   <br/>
   Check: Package existence for "make-3.79"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 make-3.79.1-17.1 passed
   <br/>
   richmond1 make-3.79.1-17.1 passed
   <br/>
   Result: Package existence check passed for "make-3.79".
   <br/>
   <br/>
   Check: Package existence for "binutils-2.14"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 binutils-2.14.90.0.4-42 passed
   <br/>
   richmond1 binutils-2.14.90.0.4-42 passed
   <br/>
   Result: Package existence check passed for "binutils-2.14".
   <br/>
   <br/>
   Check: Package existence for "gcc-3.2"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 gcc-3.2.3-54 passed
   <br/>
   richmond1 gcc-3.2.3-54 passed
   <br/>
   Result: Package existence check passed for "gcc-3.2".
   <br/>
   <br/>
   Check: Package existence for "glibc-2.3.2-95.27"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 glibc-2.3.2-95.39 passed
   <br/>
   richmond1 glibc-2.3.2-95.39 passed
   <br/>
   Result: Package existence check passed for "glibc-2.3.2-95.27".
   <br/>
   <br/>
   Check: Package existence for "compat-db-4.0.14-5"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 compat-db-4.0.14-5.1 passed
   <br/>
   richmond1 compat-db-4.0.14-5.1 passed
   <br/>
   Result: Package existence check passed for "compat-db-4.0.14-5".
   <br/>
   <br/>
   Check: Package existence for "compat-gcc-7.3-2.96.128"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 compat-gcc-7.3-2.96.128 passed
   <br/>
   richmond1 compat-gcc-7.3-2.96.128 passed
   <br/>
   Result: Package existence check passed for "compat-gcc-7.3-2.96.128".
   <br/>
   <br/>
   Check: Package existence for "compat-gcc-c++-7.3-2.96.128"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 compat-gcc-c++-7.3-2.96.128 passed
   <br/>
   richmond1 compat-gcc-c++-7.3-2.96.128 passed
   <br/>
   Result: Package existence check passed for "compat-gcc-c++-7.3-2.96.128".
   <br/>
   <br/>
   Check: Package existence for "compat-libstdc++-7.3-2.96.128"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 compat-libstdc++-7.3-2.96.128 passed
   <br/>
   richmond1 compat-libstdc++-7.3-2.96.128 passed
   <br/>
   Result: Package existence check passed for "compat-libstdc++-7.3-2.96.128".
   <br/>
   <br/>
   Check: Package existence for "compat-libstdc++-devel-7.3-2.96.128"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 compat-libstdc++-devel-7.3-2.96.128 passed
   <br/>
   richmond1 compat-libstdc++-devel-7.3-2.96.128 passed
   <br/>
   Result: Package existence check passed for "compat-libstdc++-devel-7.3-2.96.128".
   <br/>
   <br/>
   Check: Package existence for "openmotif-2.2.3"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 openmotif-2.2.3-5.RHEL3.2 passed
   <br/>
   richmond1 openmotif-2.2.3-5.RHEL3.2 passed
   <br/>
   Result: Package existence check passed for "openmotif-2.2.3".
   <br/>
   <br/>
   Check: Package existence for "setarch-1.3-1"
   <br/>
   Node Name Status Comment
   <br/>
   ------------------------------ ------------------------------ ----------------
   <br/>
   richmond2 setarch-1.3-1 passed
   <br/>
   richmond1 setarch-1.3-1 passed
   <br/>
   Result: Package existence check passed for "setarch-1.3-1".
   <br/>
   <br/>
   Check: Group existence for "dba"
   <br/>
   Node Name Status Comment
   <br/>
   ------------ ------------------------ ------------------------
   <br/>
   richmond2 exists passed
   <br/>
   richmond1 exists passed
   <br/>
   Result: Group existence check passed for "dba".
   <br/>
   <br/>
   Check: Group existence for "oinstall"
   <br/>
   Node Name Status Comment
   <br/>
   ------------ ------------------------ ------------------------
   <br/>
   richmond2 exists passed
   <br/>
   richmond1 exists passed
   <br/>
   Result: Group existence check passed for "oinstall".
   <br/>
   <br/>
   Check: User existence for "nobody"
   <br/>
   Node Name Status Comment
   <br/>
   ------------ ------------------------ ------------------------
   <br/>
   richmond2 exists passed
   <br/>
   richmond1 exists passed
   <br/>
   Result: User existence check passed for "nobody".
   <br/>
   <br/>
   System requirement passed for 'crs'
   <br/>
   <br/>
   <br/>
   Pre-check for cluster services setup was unsuccessful on all the nodes.
  </code>
 </p>
 <p>
  The only issues are the VIP problem and the disk shareability which I know about and accept.
 </p>
</div>
