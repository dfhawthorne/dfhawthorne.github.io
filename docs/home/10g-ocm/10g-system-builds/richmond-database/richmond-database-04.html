---
layout: default
title: Richmond Database (04)
base-url: home/10g-ocm/10g-system-builds/richmond-database/richmond-database-04.html
breadcrumbs:
- title: Home
  url: index.html
- title: 10G OCM
  url: home/10g-ocm.html
- title: 10G System Builds
  url: home/10g-ocm/10g-system-builds.html
- title: Richmond Database
  url: home/10g-ocm/10g-system-builds/richmond-database.html
- title: Richmond Database (04)
  url: home/10g-ocm/10g-system-builds/richmond-database/richmond-database-04.html
scroll-bar:
  left-link:
    url: home/10g-ocm/10g-system-builds/richmond-database/richmond-database-03.html
    title: Richmond Database (03)
  right-link:
    url: /home/10g-ocm/10g-system-builds/richmond-database/richmond-database-05.html
    title: Richmond Database (05)
---
<div dir="ltr">
 <p style="font-size:smaller;font-style:italic">
  Saturday 17 May, 2008 - 21:56
 </p>
 <p>
  <code>
   /var/log/messages
  </code>
  shows the following after starting
  <b>
   richmond2
  </b>
  :
  <br/>
  <code>
   richmond2 logger: Oracle CSS daemon failed to start up. Check CRS logs for diagnostics.
  </code>
 </p>
 <p>
  <code>
   /u00/crs/oracle/product/10/app/log/richmond2/cssd/ocssd.log
  </code>
  shows a copious amount of information amongst which is:
  <br/>
  <code>
   &gt;USER: Oracle Database 10g CSS Release 10.2.0.1.0 Production Copyright 1996, 2004 Oracle. All rights reserved.
   <br/>
   &gt;USER: CSS daemon log for node richmond2, number 2, in cluster richmond
   <br/>
   [ clsdmt]Listening to (ADDRESS=(PROTOCOL=ipc)(KEY=richmond2DBG_CSSD))
   <br/>
   &gt;TRACE: clssscmain: local-only set to false
   <br/>
   &gt;TRACE: clssnmReadNodeInfo: added node 1 (richmond1) to cluster
   <br/>
   &gt;TRACE: clssnmReadNodeInfo: added node 2 (richmond2) to cluster
   <br/>
   <b>
    &gt;TRACE: clssnm_skgxnmon: skgxn init failed, rc 1
   </b>
   <br/>
   &gt;TRACE: clssnm_skgxnonline: Using vacuous skgxn monitor
   <br/>
   &gt;TRACE: clssnmDiskStateChange: state from 1 to 2 disk (0//dev/raw/raw2)
   <br/>
   &gt;TRACE: clssnmDiskStateChange: state from 1 to 2 disk (1//dev/raw/raw17)
   <br/>
   &gt;TRACE: clssnmDiskStateChange: state from 1 to 2 disk (2//dev/raw/raw32)
   <br/>
   &gt;TRACE: clssnmDiskStateChange: state from 2 to 4 disk (0//dev/raw/raw2)
   <br/>
   &gt;TRACE: clssnmDiskStateChange: state from 2 to 4 disk (1//dev/raw/raw17)
   <br/>
   &gt;TRACE: clssnmReadDskHeartbeat: node(1) is down. rcfg(2) wrtcnt(8321) LATS(0) Disk lastSeqNo(8321)
   <br/>
   &gt;TRACE: clssnmReadDskHeartbeat: node(1) is down. rcfg(2) wrtcnt(8321) LATS(0) Disk lastSeqNo(8321)
   <br/>
   &gt;TRACE: clssnmDiskStateChange: state from 2 to 4 disk (2//dev/raw/raw32)
   <br/>
   &gt;TRACE: clssnmReadDskHeartbeat: node(1) is down. rcfg(2) wrtcnt(8322) LATS(0) Disk lastSeqNo(8322)
   <br/>
   <b>
    &gt;TRACE: clssnmFatalInit: fatal mode enabled
   </b>
   <br/>
   &gt;TRACE: clssnmconnect: connecting to node 2, flags 0x0001, connector 1
   <br/>
   &gt;TRACE: clssnmconnect: connecting to node 0, flags 0x0000, connector 1
   <br/>
   &gt;TRACE: clssnmconnect: connecting to node 1, flags 0x0001, connector 0
   <br/>
   &gt;TRACE: clssgmclientlsnr: listening on (ADDRESS=(PROTOCOL=ipc)(KEY=Oracle_CSS_LclLstnr_richmond_2))
   <br/>
   &gt;TRACE: clssgmclientlsnr: listening on (ADDRESS=(PROTOCOL=ipc)(KEY=OCSSD_LL_richmond2_richmond))
   <br/>
   &gt;TRACE: clssnmReadDskHeartbeat: node(1) is down. rcfg(2) wrtcnt(8322) LATS(9049470) Disk lastSeqNo(8322)
   <br/>
   ...
   <br/>
   &gt;TRACE: clsc_send_msg: (0x96679a8) NS err (12571, 12560), transport (530, 113, 0)
   <br/>
   <br/>
   <b>
    &gt;ERROR: clssnmInitialMsg: send failed, con (0x9667e20), rc 3
   </b>
   <br/>
   ...
   <br/>
   &gt;TRACE: clssnmReadDskHeartbeat: node(1) is down. rcfg(2) wrtcnt(8380) LATS(9110800) Disk lastSeqNo(8380)
   <br/>
   &gt;TRACE: clssnmCheckDskInfo: detected active cluster node 1
   <br/>
   &gt;ERROR: clssnmCheckDskInfo: Found cluster with node 1, state 3, incarn 2
  </code>
 </p>
 <p>
  What appears to be happening is that there is a split-brain going on.
  <b>
   richmond2
  </b>
  can see that
  <b>
   richmond1
  </b>
  is alive in the cluster but is unable to communicate to it. The existence is seen through the clssnmReadDskHeartbeat calls to the OCR disks.
 </p>
 <p>
  In other words, the interconnect is down for some reason. This is confirmed by the pings returning host unreachable messages.
 </p>
 <p>
  The question is now why the interconnect is not responding.
 </p>
</div>
